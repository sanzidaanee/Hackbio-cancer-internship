{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad02c050-cd52-4b4e-9dcd-241555ea915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load metadata and normalized data using the direct download links\n",
    "normalized_data_url = 'https://drive.google.com/uc?id=1E7xFeh2C7IYG4dTW8bCwfABJphAKHq0_'\n",
    "metadata_url = 'https://drive.google.com/uc?id=1VqL4hjYY4vcRcneaKRP9rKg7Zc3NCwLy'\n",
    "\n",
    "# Load the data into pandas DataFrames\n",
    "normalized_data = pd.read_csv(normalized_data_url)\n",
    "\n",
    "metadata = pd.read_csv(metadata_url)\n",
    "\n",
    "# 2. Prepare data for ML\n",
    "# Set the Barcode as the index for metadata\n",
    "metadata.set_index('Barcode', inplace=True)\n",
    "\n",
    "# Ensure the Barcode match between normalized data and metadata\n",
    "common_samples = normalized_data.columns.intersection(metadata.index)\n",
    "\n",
    "# Subset both datasets to include only common samples\n",
    "normalized_data = normalized_data[common_samples]\n",
    "metadata = metadata.loc[common_samples]\n",
    "\n",
    "# 3. Set the classification target\n",
    "# Using \"IDH\" as the target\n",
    "X = normalized_data.T # Transpose to have samples as rows and genes as columns\n",
    "y = metadata['IDH'] # Target labels\n",
    "\n",
    "# Split data into training and test sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Perform Feature Selection using Recursive Feature Elimination (RFE)\n",
    "# Define Random Forest as the estimator\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest on the training data\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the feature importance from the trained Random Forest model\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to hold feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order to get the top 100 features\n",
    "top_100_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(100)\n",
    "\n",
    "# Display the top 100 important features\n",
    "print(top_100_features)\n",
    "\n",
    "# Filter the dataset to only include the top 100 features\n",
    "selected_features = top_100_features['Feature'].tolist()\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# 5. Train the Random Forest classifier on the selected features\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# 6. Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test_selected)\n",
    "\n",
    "# 7. Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of Random Forest classifier: {accuracy:.2f}\")\n",
    "\n",
    "# Print confusion matrix and classification report\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# 8. Save the selected genes to a file\n",
    "selected_genes = pd.Series(selected_features)\n",
    "selected_genes.to_csv('selected_genes.csv', index=False)\n",
    "\n",
    "# 9. Plot the importance of the selected features\n",
    "importances = rf_model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1][:10] # Top 10 features\n",
    "\n",
    "# Plot top 10 important features\n",
    "plt.figure()\n",
    "plt.title(\"Top 10 Feature Importances\")\n",
    "plt.bar(range(10), importances[indices], align=\"center\")\n",
    "plt.xticks(range(10), [selected_features[i] for i in indices], rotation=90)\n",
    "plt.show()\n",
    "\n",
    " # Create a DataFrame with results\n",
    "results_df = pd.DataFrame({\n",
    "    'barcode': X_test_selected.index,  # Barcode or sample name\n",
    "    'true_sample_type': y_test,  # True sample type from metadata\n",
    "    'predicted_sample_type': y_pred,  # Predicted sample type\n",
    "    'model_accuracy': accuracy,  # Overall accuracy of the model\n",
    "    'selected_features': \"; \".join(map(str,selected_features))  # Concatenate selected feature names into a single string\n",
    "})\n",
    "\n",
    "# Display the results DataFrame\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
